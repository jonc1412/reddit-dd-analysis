{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping https://stockanalysis.com/list/sp-500-stocks/ to get S&P500 data\n",
    "#Using BS to get all the tickers from the website\n",
    "\n",
    "url = \"https://stockanalysis.com/list/sp-500-stocks/\"\n",
    "r = requests.get(url)\n",
    "html_data = r.text\n",
    "soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "\n",
    "spTickers = []\n",
    "\n",
    "elements = soup.find_all(class_=\"sym svelte-eurwtr\")\n",
    "for e in elements[1:]:\n",
    "    ticker = e.text\n",
    "    if \".\" in ticker:\n",
    "        ticker = ticker.replace(\".\", \"-\")\n",
    "    spTickers.append(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trohehe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'MyAPI/0.0.1',\n",
       " 'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzMwNjA5NzIwLjQ1MzU0LCJpYXQiOjE3MzA1MjMzMjAuNDUzNTM5LCJqdGkiOiItLWY3TUpPVkszeHpfdmhNNlN3VTUzeVpxWGxXS3ciLCJjaWQiOiJSMkxtZmI2TzJxREctMXZULVBOM0N3IiwibGlkIjoidDJfd3lhYWoyZSIsImFpZCI6InQyX3d5YWFqMmUiLCJsY2EiOjE1MTg1ODEwODM5MTUsInNjcCI6ImVKeUtWdEpTaWdVRUFBRF9fd056QVNjIiwiZmxvIjo5fQ.Afvz8g6fnYYpXRNb-ruyXZNbQY-fNyzuGgxoaBNKpu_BxhrM9fcpZ07VnKJIkiNCsz27ohzxb-t8ni6ksKKOxILG5vzFhtjTIkqX0NC4furpvBhx0MqDJVdr7WPD_EPh_yy7Q40EcBpCXnnnKlFmCTb6k8ng_YIKooyCMLeKmzwNDhNTkx3NGW1GXtsV1DZABxrmgMuLKnu2FSOAn7RBg19Ea9rCSbCVEcpdWe1Ym-5kKWCGipGd_Txz2_B-vTCn3WGNNWUkcq6Mj-ur-qHdzHhcFs1mnPGBAKACZwB0c2eirwDr-aGvUHKlGG_OWTo3Z7Tts2Dwshpcd4B0t4Jblg'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing reddit api\n",
    "secret_key = os.getenv('rSECRETKEY')\n",
    "client_id = os.getenv('rCLIENTID')\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(client_id,secret_key)\n",
    "\n",
    "login_data = {\n",
    "    'grant_type' : 'password',\n",
    "    'username' : os.getenv('rUSERNAME'),\n",
    "    'password' : os.getenv('rPASSWORD')\n",
    "}\n",
    "\n",
    "headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
    "\n",
    "response = requests.post('https://www.reddit.com/api/v1/access_token',auth=auth,data=login_data, headers=headers)\n",
    "response.json()\n",
    "token = response.json()['access_token']\n",
    "headers = {**headers, **{'Authorization': f'bearer {token}'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing Wallstreetbets subreddit for posts with the flair:DD and retrieving the Titles\n",
    "dd_comp = []\n",
    "dd_desc = []\n",
    "params = {'limit': 100}\n",
    "\n",
    "while True:\n",
    "\n",
    "    r_wsbs = requests.get('https://oauth.reddit.com/r/wallstreetbets/',headers=headers, params=params)\n",
    "    data = r_wsbs.json()['data']\n",
    "\n",
    "    for post in data['children']:\n",
    "        if post['data']['link_flair_css_class'] == 'dd':\n",
    "            dd_comp.append(post['data']['title'])\n",
    "            dd_desc.append(post['data']['selftext'])\n",
    "\n",
    "    if 'after' in data and data['after']:\n",
    "        params['after'] = data['after']\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requesting stock data from alphavantage api (limited use to 25 api calls a day)\n",
    "\n",
    "func = \"TIME_SERIES_INTRADAY\"\n",
    "interval = \"60min\"\n",
    "ticker = \"NVDA\"\n",
    "api_key = os.getenv('aAPIKEY')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function={func}&symbol={ticker}&interval={interval}&apikey={api_key}\"\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "info_data = data[\"Meta Data\"]\n",
    "time_data = data[f\"Time Series ({interval})\"]\n",
    "\n",
    "for k, v in info_data.items():\n",
    "    df[k[3:]] = [v]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
